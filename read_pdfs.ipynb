{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF4\n",
    "from PyPDF4 import PdfFileReader\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Author': 'Timo Schick ; Hinrich Sch√ºtze',\n",
       " '/CreationDate': \"D:20210910121624+02'00'\",\n",
       " '/Creator': 'LaTeX with hyperref',\n",
       " '/Keywords': '',\n",
       " '/ModDate': \"D:20210910121624+02'00'\",\n",
       " '/PTEX.Fullbanner': 'This is MiKTeX-pdfTeX 4.6.1 (1.40.22)',\n",
       " '/Producer': 'MiKTeX pdfTeX-1.40.22',\n",
       " '/Subject': 'EMNLP 2021',\n",
       " '/Title': 'Generating Datasets with Pretrained Language Models',\n",
       " '/Trapped': '/False'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = PdfFileReader(\"generating_datasets_lm.pdf\")\n",
    "lm.getDocumentInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lm.is_encrypted:\n",
    "    lm.decrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Get number of pages in the file\n",
    "print(lm.getNumPages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pdf into text file\n",
    "\n",
    "number_of_pages = lm.getNumPages()\n",
    "isRecording = False\n",
    "arr_strs = []\n",
    "\n",
    "page_content = \"\"                # define variable for using in loop.\n",
    "pattern = \"1 Introduction\\n(?:.|\\n)*References\"\n",
    "with open('generating_datasets_lm.txt', 'w', encoding=\"utf8\") as f_op:\n",
    "    \n",
    "    for page_number in range(0, number_of_pages-1):\n",
    "        page = lm.getPage(page_number)\n",
    "        page_content += page.extractText()     # concat reading pages.\n",
    "    content_to_match = re.findall(pattern, page_content,re.MULTILINE)\n",
    "    #print(content_to_match)\n",
    "#     if content_to_match:\n",
    "#         f_op.writelines(arr_strs)\n",
    "#     for p in page_content:\n",
    "#         print(p)\n",
    "#         content_to_match = re.search(pattern, p)\n",
    "        #print(content_to_match)\n",
    "#         if content_to_match:\n",
    "#             f_op.writelines(arr_strs)\n",
    "#         if re.search(r\"1 Introduction\", page_content):\n",
    "#             isRecording = True\n",
    "#         if isRecording:\n",
    "#             arr_strs.append(page_content)\n",
    "#         if re.search(r\"References\", page_content):\n",
    "#             break\n",
    "    f_op.writelines(content_to_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70\n",
    "# Clean the input document\n",
    "def read_file(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    paper = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "    for sentence in paper:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "        sentences.pop()\n",
    "    return sentencces\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69717ce88e574254a5876d1648f1e44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sgupt\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development [file_download.py:127]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2e71b86d184e67b5f290448cc4c74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb89b47da114af4ae76ca3a5c8c554d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24395b85bc874c0bba6decf2f74c567e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab185ee6502479bac44689fc9656d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'sshleifer/distilbart-cnn-12-6'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zero-shot summary\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer.model.config.__getattribute__('_name_or_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
